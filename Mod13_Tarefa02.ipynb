{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from stepwise_regression import step_reg\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import patsy\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>posse_de_veiculo</th>\n",
       "      <th>posse_de_imovel</th>\n",
       "      <th>qtd_filhos</th>\n",
       "      <th>tipo_renda</th>\n",
       "      <th>educacao</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>tipo_residencia</th>\n",
       "      <th>idade</th>\n",
       "      <th>tempo_emprego</th>\n",
       "      <th>qt_pessoas_residencia</th>\n",
       "      <th>renda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Empresário</td>\n",
       "      <td>Secundário</td>\n",
       "      <td>Solteiro</td>\n",
       "      <td>Casa</td>\n",
       "      <td>26</td>\n",
       "      <td>6.602740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8060.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Assalariado</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado</td>\n",
       "      <td>Casa</td>\n",
       "      <td>28</td>\n",
       "      <td>7.183562</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1852.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Empresário</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado</td>\n",
       "      <td>Casa</td>\n",
       "      <td>35</td>\n",
       "      <td>0.838356</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2253.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Servidor público</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado</td>\n",
       "      <td>Casa</td>\n",
       "      <td>30</td>\n",
       "      <td>4.846575</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6600.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Assalariado</td>\n",
       "      <td>Secundário</td>\n",
       "      <td>Solteiro</td>\n",
       "      <td>Governamental</td>\n",
       "      <td>33</td>\n",
       "      <td>4.293151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6475.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sexo  posse_de_veiculo  posse_de_imovel  qtd_filhos        tipo_renda  \\\n",
       "0    F             False             True           0        Empresário   \n",
       "1    M              True             True           0       Assalariado   \n",
       "2    F              True             True           0        Empresário   \n",
       "3    F             False             True           1  Servidor público   \n",
       "4    M              True            False           0       Assalariado   \n",
       "\n",
       "            educacao estado_civil tipo_residencia  idade  tempo_emprego  \\\n",
       "0         Secundário     Solteiro            Casa     26       6.602740   \n",
       "1  Superior completo       Casado            Casa     28       7.183562   \n",
       "2  Superior completo       Casado            Casa     35       0.838356   \n",
       "3  Superior completo       Casado            Casa     30       4.846575   \n",
       "4         Secundário     Solteiro   Governamental     33       4.293151   \n",
       "\n",
       "   qt_pessoas_residencia    renda  \n",
       "0                    1.0  8060.34  \n",
       "1                    2.0  1852.15  \n",
       "2                    2.0  2253.89  \n",
       "3                    3.0  6600.77  \n",
       "4                    1.0  6475.97  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "df.drop(['Unnamed: 0', 'id_cliente', 'data_ref'], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop('renda', axis=1), drop_first = True)\n",
    "y = df['renda']\n",
    "X.values.reshape(1,-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, \n",
    "                                                    train_size= 0.75, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "0.2847067205249384\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "parameters = {'alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "ridge_regression = GridSearchCV(ridge, parameters, scoring='r2', cv=None)\n",
    "ridge_regression.fit(X_test, y_test)\n",
    "print(ridge_regression.best_params_)\n",
    "print(ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.460e+10, tolerance: 1.295e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e+10, tolerance: 1.341e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+10, tolerance: 1.487e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.058e+10, tolerance: 1.476e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.988e+10, tolerance: 1.438e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.455e+10, tolerance: 1.295e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.743e+10, tolerance: 1.341e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e+10, tolerance: 1.487e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e+10, tolerance: 1.476e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.984e+10, tolerance: 1.438e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.432e+10, tolerance: 1.295e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.730e+10, tolerance: 1.341e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+10, tolerance: 1.487e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.036e+10, tolerance: 1.476e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.971e+10, tolerance: 1.438e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+10, tolerance: 1.295e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.713e+10, tolerance: 1.341e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e+10, tolerance: 1.487e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e+10, tolerance: 1.476e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.953e+10, tolerance: 1.438e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.081e+10, tolerance: 1.295e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.568e+10, tolerance: 1.341e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.882e+10, tolerance: 1.487e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.789e+10, tolerance: 1.476e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.798e+10, tolerance: 1.438e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.261e+10, tolerance: 1.295e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.344e+10, tolerance: 1.341e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.628e+10, tolerance: 1.487e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.363e+10, tolerance: 1.476e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.553e+10, tolerance: 1.438e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.470e+10, tolerance: 1.759e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Lasso(),\n",
       "             param_grid={'alpha': [0, 0.001, 0.005, 0.01, 0.05, 0.1]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "parameters = {'alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "lasso_regression = GridSearchCV(lasso, parameters, scoring='r2', cv=None)\n",
    "lasso_regression.fit(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "0.2846697676746014\n"
     ]
    }
   ],
   "source": [
    "print(lasso_regression.best_params_)\n",
    "print(lasso_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "df.drop(['Unnamed: 0', 'id_cliente', 'data_ref'], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "X = pd.get_dummies(df1.drop('renda', axis=1), drop_first = True)\n",
    "y = df['renda']\n",
    "X = X.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, \n",
    "                                                    train_size= 0.75, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107, 24)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1705.55,\n",
       " 1748.99,\n",
       " 1733.67,\n",
       " 2378.25,\n",
       " 1957.87,\n",
       " 1218.39,\n",
       " 2085.39,\n",
       " 8849.5,\n",
       " 4676.05,\n",
       " 1915.48,\n",
       " 3356.47,\n",
       " 4264.23,\n",
       " 2247.23,\n",
       " 1666.38,\n",
       " 5250.55,\n",
       " 2872.99,\n",
       " 5025.98,\n",
       " 8522.41,\n",
       " 2416.77,\n",
       " 7620.51,\n",
       " 1820.84,\n",
       " 2684.77,\n",
       " 1043.34,\n",
       " 21332.93,\n",
       " 5045.4,\n",
       " 3906.16,\n",
       " 1728.92,\n",
       " 17555.6,\n",
       " 3405.61,\n",
       " 8929.22,\n",
       " 2928.12,\n",
       " 3421.45,\n",
       " 4045.44,\n",
       " 18805.6,\n",
       " 4742.33,\n",
       " 1486.95,\n",
       " 2081.38,\n",
       " 14385.5,\n",
       " 3707.71,\n",
       " 4154.05,\n",
       " 1240.38,\n",
       " 3604.4,\n",
       " 18298.97,\n",
       " 2974.18,\n",
       " 27089.27,\n",
       " 5240.19,\n",
       " 2037.0,\n",
       " 2923.9,\n",
       " 17376.58,\n",
       " 6166.65,\n",
       " 1547.03,\n",
       " 3349.37,\n",
       " 1174.45,\n",
       " 6579.83,\n",
       " 4221.19,\n",
       " 564.78,\n",
       " 5834.37,\n",
       " 15375.48,\n",
       " 3037.0,\n",
       " 1878.91,\n",
       " 1458.83,\n",
       " 3362.06,\n",
       " 15919.06,\n",
       " 1303.38,\n",
       " 2802.44,\n",
       " 2440.24,\n",
       " 3255.03,\n",
       " 9530.44,\n",
       " 1407.43,\n",
       " 1829.94,\n",
       " 4855.44,\n",
       " 3505.43,\n",
       " 2317.6,\n",
       " 23013.28,\n",
       " 6772.53,\n",
       " 9001.2,\n",
       " 1800.49,\n",
       " 462.43,\n",
       " 371.94,\n",
       " 2725.28,\n",
       " 13425.06,\n",
       " 11032.31,\n",
       " 8048.85,\n",
       " 1052.59,\n",
       " 3011.85,\n",
       " 5302.23,\n",
       " 6806.95,\n",
       " 6100.4,\n",
       " 2379.06,\n",
       " 3398.81,\n",
       " 1899.62,\n",
       " 3302.63,\n",
       " 2644.74,\n",
       " 2139.6,\n",
       " 4276.78,\n",
       " 1090.68,\n",
       " 9254.05,\n",
       " 3971.34,\n",
       " 4788.9,\n",
       " 1122.29,\n",
       " 9795.7,\n",
       " 1592.57,\n",
       " 6666.96,\n",
       " 1458.5,\n",
       " 1976.09,\n",
       " 5791.62,\n",
       " 3211.34,\n",
       " 8392.05,\n",
       " 3081.21,\n",
       " 2471.69,\n",
       " 4880.34,\n",
       " 4046.42,\n",
       " 9209.56,\n",
       " 902.4,\n",
       " 6130.62,\n",
       " 1330.82,\n",
       " 18771.6,\n",
       " 5572.62,\n",
       " 2502.36,\n",
       " 1183.96,\n",
       " 2018.88,\n",
       " 1327.64,\n",
       " 3101.52,\n",
       " 3325.4,\n",
       " 727.78,\n",
       " 4067.29,\n",
       " 1923.23,\n",
       " 1037.89,\n",
       " 44048.77,\n",
       " 2085.68,\n",
       " 2750.58,\n",
       " 17202.58,\n",
       " 1110.35,\n",
       " 5673.18,\n",
       " 14007.96,\n",
       " 6713.52,\n",
       " 8593.97,\n",
       " 2142.5,\n",
       " 1089.6,\n",
       " 4888.61,\n",
       " 16575.4,\n",
       " 2678.97,\n",
       " 3363.25,\n",
       " 4704.81,\n",
       " 6919.41,\n",
       " 1991.82,\n",
       " 3660.29,\n",
       " 32693.62,\n",
       " 9251.62,\n",
       " 4101.62,\n",
       " 16211.81,\n",
       " 8100.5,\n",
       " 2471.69,\n",
       " 2500.79,\n",
       " 6540.03,\n",
       " 6213.01,\n",
       " 1941.37,\n",
       " 6223.53,\n",
       " 595.45,\n",
       " 2053.04,\n",
       " 890.45,\n",
       " 1644.86,\n",
       " 2673.88,\n",
       " 4867.69,\n",
       " 2195.15,\n",
       " 7276.7,\n",
       " 1179.11,\n",
       " 18462.08,\n",
       " 4496.93,\n",
       " 7188.37,\n",
       " 5428.47,\n",
       " 4057.54,\n",
       " 5357.39,\n",
       " 3914.64,\n",
       " 3013.3,\n",
       " 66767.67,\n",
       " 3039.2,\n",
       " 2625.75,\n",
       " 13299.29,\n",
       " 7945.5,\n",
       " 3603.28,\n",
       " 6838.95,\n",
       " 6051.94,\n",
       " 5321.22,\n",
       " 1895.17,\n",
       " 4234.94,\n",
       " 2345.64,\n",
       " 5028.98,\n",
       " 1963.24,\n",
       " 13598.92,\n",
       " 907.88,\n",
       " 5822.02,\n",
       " 1623.52,\n",
       " 2299.43,\n",
       " 5061.99,\n",
       " 4674.11,\n",
       " 4706.75,\n",
       " 2946.47,\n",
       " 11713.3,\n",
       " 1761.87,\n",
       " 1310.12,\n",
       " 6532.82,\n",
       " 4578.57,\n",
       " 6445.6,\n",
       " 3895.71,\n",
       " 5000.61,\n",
       " 3925.1,\n",
       " 4978.48,\n",
       " 701.83,\n",
       " 6522.26,\n",
       " 889.65,\n",
       " 2108.17,\n",
       " 2806.91,\n",
       " 5045.24,\n",
       " 19269.18,\n",
       " 3684.83,\n",
       " 2193.66,\n",
       " 1950.41,\n",
       " 38796.02,\n",
       " 8435.2,\n",
       " 2350.07,\n",
       " 4189.61,\n",
       " 8645.35,\n",
       " 2053.52,\n",
       " 327.51,\n",
       " 3935.71,\n",
       " 3879.51,\n",
       " 2413.12,\n",
       " 3349.37,\n",
       " 16038.07,\n",
       " 5177.04,\n",
       " 1957.57,\n",
       " 2789.98,\n",
       " 2937.22,\n",
       " 1522.45,\n",
       " 1772.62,\n",
       " 4076.02,\n",
       " 25277.37,\n",
       " 5232.15,\n",
       " 36530.49,\n",
       " 2044.93,\n",
       " 4721.11,\n",
       " 18805.6,\n",
       " 4339.98,\n",
       " 1215.4,\n",
       " 4481.39,\n",
       " 5272.58,\n",
       " 19619.86,\n",
       " 8358.38,\n",
       " 4399.36,\n",
       " 14535.94,\n",
       " 29825.62,\n",
       " 2622.07,\n",
       " 7736.4,\n",
       " 2332.21,\n",
       " 3569.06,\n",
       " 2371.51,\n",
       " 5148.4,\n",
       " 60803.32,\n",
       " 3420.34,\n",
       " 4349.39,\n",
       " 935.6,\n",
       " 3814.21,\n",
       " 875.5,\n",
       " 2139.97,\n",
       " 3383.75,\n",
       " 1228.27,\n",
       " 9826.31,\n",
       " 1191.7,\n",
       " 2914.84,\n",
       " 10832.26,\n",
       " 2614.05,\n",
       " 7042.11,\n",
       " 19090.95,\n",
       " 13155.33,\n",
       " 6618.76,\n",
       " 6436.74,\n",
       " 18238.45,\n",
       " 1502.17,\n",
       " 28299.6,\n",
       " 5780.34,\n",
       " 1434.51,\n",
       " 2152.52,\n",
       " 3890.37,\n",
       " 1253.82,\n",
       " 9675.4,\n",
       " 3684.24,\n",
       " 55122.44,\n",
       " 3319.24,\n",
       " 3271.27,\n",
       " 12773.57,\n",
       " 1990.92,\n",
       " 6659.44,\n",
       " 444.74,\n",
       " 8602.51,\n",
       " 8366.67,\n",
       " 2559.18,\n",
       " 3915.97,\n",
       " 8066.65,\n",
       " 1790.79,\n",
       " 9079.54,\n",
       " 1924.25,\n",
       " 2479.3,\n",
       " 713.19,\n",
       " 4956.11,\n",
       " 940.61,\n",
       " 5791.2,\n",
       " 2859.73,\n",
       " 2279.87,\n",
       " 8046.97,\n",
       " 1453.79,\n",
       " 2452.07,\n",
       " 6202.58,\n",
       " 9216.67,\n",
       " 967.76,\n",
       " 5274.97,\n",
       " 967.76,\n",
       " 815.66,\n",
       " 9783.86,\n",
       " 3572.06,\n",
       " 1848.78,\n",
       " 2643.47,\n",
       " 1968.42,\n",
       " 5210.42,\n",
       " 2626.1,\n",
       " 5354.29,\n",
       " 1948.02,\n",
       " 3469.59,\n",
       " 2497.52,\n",
       " 9517.47,\n",
       " 2900.87,\n",
       " 5538.88,\n",
       " 4425.04,\n",
       " 1731.06,\n",
       " 6264.02,\n",
       " 6526.81,\n",
       " 11647.85,\n",
       " 1845.07,\n",
       " 1878.78,\n",
       " 7352.4,\n",
       " 593.13,\n",
       " 4392.92,\n",
       " 12410.0,\n",
       " 4018.58,\n",
       " 1358.79,\n",
       " 1813.56,\n",
       " 12052.39,\n",
       " 3641.35,\n",
       " 4381.36,\n",
       " 5695.69,\n",
       " 5552.33,\n",
       " 9590.0,\n",
       " 5762.42,\n",
       " 2072.49,\n",
       " 7864.55,\n",
       " 5546.36,\n",
       " 2778.23,\n",
       " 2192.81,\n",
       " 2820.21,\n",
       " 2386.12,\n",
       " 2789.29,\n",
       " 1680.62,\n",
       " 9729.55,\n",
       " 5032.72,\n",
       " 1620.73,\n",
       " 10079.2,\n",
       " 4082.3,\n",
       " 3150.78,\n",
       " 9126.07,\n",
       " 10757.2,\n",
       " 16297.34,\n",
       " 2168.6,\n",
       " 1646.99,\n",
       " 11774.9,\n",
       " 6772.53,\n",
       " 2962.46,\n",
       " 2315.28,\n",
       " 6252.39,\n",
       " 13184.94,\n",
       " 2756.54,\n",
       " 4669.8,\n",
       " 1822.95,\n",
       " 3830.08,\n",
       " 4141.48,\n",
       " 2584.0,\n",
       " 3622.28,\n",
       " 2228.23,\n",
       " 1646.69,\n",
       " 107414.21,\n",
       " 2593.57,\n",
       " 6914.16,\n",
       " 5431.18,\n",
       " 1121.75,\n",
       " 3217.05,\n",
       " 1798.52,\n",
       " 7656.61,\n",
       " 2599.08,\n",
       " 2192.52,\n",
       " 1616.25,\n",
       " 14696.09,\n",
       " 339.36,\n",
       " 3738.66,\n",
       " 728.96,\n",
       " 4874.62,\n",
       " 1642.86,\n",
       " 3479.89,\n",
       " 1109.65,\n",
       " 10529.47,\n",
       " 3377.28,\n",
       " 1197.85,\n",
       " 15779.34,\n",
       " 8089.09,\n",
       " 13620.35,\n",
       " 9979.33,\n",
       " 2996.85,\n",
       " 1995.04,\n",
       " 2312.46,\n",
       " 4198.55,\n",
       " 2997.11,\n",
       " 15296.5,\n",
       " 2055.21,\n",
       " 8696.36,\n",
       " 3681.05,\n",
       " 6747.13,\n",
       " 1802.86,\n",
       " 2690.13,\n",
       " 3215.16,\n",
       " 3322.93,\n",
       " 6986.26,\n",
       " 2266.57,\n",
       " 2163.41,\n",
       " 4462.83,\n",
       " 30592.71,\n",
       " 2321.36,\n",
       " 15410.45,\n",
       " 5406.65,\n",
       " 5800.74,\n",
       " 4719.34,\n",
       " 939.04,\n",
       " 14152.48,\n",
       " 2715.22,\n",
       " 4326.66,\n",
       " 4475.3,\n",
       " 3013.84,\n",
       " 12773.57,\n",
       " 2068.46,\n",
       " 1719.55,\n",
       " 5568.55,\n",
       " 2100.41,\n",
       " 4679.37,\n",
       " 2154.36,\n",
       " 5555.36,\n",
       " 4315.34,\n",
       " 1743.44,\n",
       " 2184.97,\n",
       " 871.22,\n",
       " 2655.03,\n",
       " 4126.47,\n",
       " 12752.66,\n",
       " 9160.54,\n",
       " 4584.83,\n",
       " 2635.55,\n",
       " 2168.67,\n",
       " 956.9,\n",
       " 3787.3,\n",
       " 2306.5,\n",
       " 2214.17,\n",
       " 2298.63,\n",
       " 4564.76,\n",
       " 4104.5,\n",
       " 14031.23,\n",
       " 3872.76,\n",
       " 3549.67,\n",
       " 1611.18,\n",
       " 13691.52,\n",
       " 6752.2,\n",
       " 6078.57,\n",
       " 1094.33,\n",
       " 1915.04,\n",
       " 2218.56,\n",
       " 22464.67,\n",
       " 4508.86,\n",
       " 1546.27,\n",
       " 5887.87,\n",
       " 8598.39,\n",
       " 4574.73,\n",
       " 18297.17,\n",
       " 2863.05,\n",
       " 2451.26,\n",
       " 1926.09,\n",
       " 4254.33,\n",
       " 9392.83,\n",
       " 2043.22,\n",
       " 488.41,\n",
       " 1223.06,\n",
       " 4937.18,\n",
       " 3472.39,\n",
       " 803.3,\n",
       " 29010.82,\n",
       " 16769.7,\n",
       " 8182.88,\n",
       " 5501.49,\n",
       " 7924.72,\n",
       " 613.97,\n",
       " 1651.38,\n",
       " 1085.39,\n",
       " 6165.77,\n",
       " 3818.0,\n",
       " 7414.63,\n",
       " 29224.79,\n",
       " 2007.63,\n",
       " 9580.6,\n",
       " 2467.76,\n",
       " 2258.35,\n",
       " 1933.65,\n",
       " 2115.49,\n",
       " 9618.12,\n",
       " 2571.0,\n",
       " 4918.3,\n",
       " 8350.25,\n",
       " 2637.05,\n",
       " 2121.22,\n",
       " 5498.32,\n",
       " 8370.15,\n",
       " 9323.81,\n",
       " 4065.28,\n",
       " 5288.66,\n",
       " 926.7,\n",
       " 14043.07,\n",
       " 3174.21,\n",
       " 10978.3,\n",
       " 2267.6,\n",
       " 7620.51,\n",
       " 3619.63,\n",
       " 2723.0,\n",
       " 3653.47,\n",
       " 3324.02,\n",
       " 1576.48,\n",
       " 1709.11,\n",
       " 12682.85,\n",
       " 1156.9,\n",
       " 9517.47,\n",
       " 1056.42,\n",
       " 3394.7,\n",
       " 4496.45,\n",
       " 1640.45,\n",
       " 14468.09,\n",
       " 44260.54,\n",
       " 1485.62,\n",
       " 1131.01,\n",
       " 18891.81,\n",
       " 7647.99,\n",
       " 1217.68,\n",
       " 1696.96,\n",
       " 7463.3,\n",
       " 5431.18,\n",
       " 2384.65,\n",
       " 8264.29,\n",
       " 10874.46,\n",
       " 3636.53,\n",
       " 1260.22,\n",
       " 762.72,\n",
       " 1980.53,\n",
       " 11267.4,\n",
       " 24784.89,\n",
       " 327.51,\n",
       " 675.4,\n",
       " 3853.53,\n",
       " 15913.06,\n",
       " 18630.45,\n",
       " 1867.42,\n",
       " 1587.66,\n",
       " 2561.94,\n",
       " 4641.8,\n",
       " 1849.76,\n",
       " 1291.84,\n",
       " 2875.88,\n",
       " 2957.31,\n",
       " 747.4,\n",
       " 7958.21,\n",
       " 1706.16,\n",
       " 2166.72,\n",
       " 2238.8,\n",
       " 1001.98,\n",
       " 24691.33,\n",
       " 3895.71,\n",
       " 4136.66,\n",
       " 4217.92,\n",
       " 11906.09,\n",
       " 4846.91,\n",
       " 6128.45,\n",
       " 1856.09,\n",
       " 2038.43,\n",
       " 7192.27,\n",
       " 2132.68,\n",
       " 3492.16,\n",
       " 77676.54,\n",
       " 4599.6,\n",
       " 5256.0,\n",
       " 3456.57,\n",
       " 3551.22,\n",
       " 1571.86,\n",
       " 6136.99,\n",
       " 5568.69,\n",
       " 7994.04,\n",
       " 1673.38,\n",
       " 4056.32,\n",
       " 2946.47,\n",
       " 5171.52,\n",
       " 24708.5,\n",
       " 3012.96,\n",
       " 786.06,\n",
       " 5713.31,\n",
       " 5386.75,\n",
       " 10348.05,\n",
       " 3645.11,\n",
       " 4937.18,\n",
       " 3166.95,\n",
       " 3576.22,\n",
       " 1169.8,\n",
       " 11545.7,\n",
       " 19619.86,\n",
       " 707.96,\n",
       " 2727.78,\n",
       " 7765.11,\n",
       " 4118.34,\n",
       " 2064.84,\n",
       " 2098.72,\n",
       " 1799.7,\n",
       " 13143.77,\n",
       " 3459.32,\n",
       " 6678.37,\n",
       " 2758.02,\n",
       " 10017.83,\n",
       " 2484.35,\n",
       " 8651.81,\n",
       " 10639.79,\n",
       " 3043.08,\n",
       " 3458.96,\n",
       " 3352.27,\n",
       " 3765.75,\n",
       " 5932.84,\n",
       " 1882.27,\n",
       " 6569.62,\n",
       " 2243.46,\n",
       " 10840.96,\n",
       " 4101.62,\n",
       " 2207.64,\n",
       " 458.35,\n",
       " 3393.17,\n",
       " 5267.09,\n",
       " 3827.48,\n",
       " 2449.39,\n",
       " 765.74,\n",
       " 1683.36,\n",
       " 23824.73,\n",
       " 7637.98,\n",
       " 1029.58,\n",
       " 2556.29,\n",
       " 1027.64,\n",
       " 3461.08,\n",
       " 6144.37,\n",
       " 4003.9,\n",
       " 1131.01,\n",
       " 6479.07,\n",
       " 1352.27,\n",
       " 10952.51,\n",
       " 1919.24,\n",
       " 1002.52,\n",
       " 29798.68,\n",
       " 2227.1,\n",
       " 2152.79,\n",
       " 1665.1,\n",
       " 16588.65,\n",
       " 7406.64,\n",
       " 2557.53,\n",
       " 1097.01,\n",
       " 2521.34,\n",
       " 15707.93,\n",
       " 7266.5,\n",
       " 4892.81,\n",
       " 10719.9,\n",
       " 4541.72,\n",
       " 5178.45,\n",
       " 6140.73,\n",
       " 29278.26,\n",
       " 11263.82,\n",
       " 11906.09,\n",
       " 2180.3,\n",
       " 3865.05,\n",
       " 1627.38,\n",
       " 6569.31,\n",
       " 9372.32,\n",
       " 1111.4,\n",
       " 2062.81,\n",
       " 4213.92,\n",
       " 5555.98,\n",
       " 3317.12,\n",
       " 1219.25,\n",
       " 6164.15,\n",
       " 1433.86,\n",
       " 1492.85,\n",
       " 6678.37,\n",
       " 2439.12,\n",
       " 3486.61,\n",
       " 2655.59,\n",
       " 4546.49,\n",
       " 5913.07,\n",
       " 2674.84,\n",
       " 1059.31,\n",
       " 4137.41,\n",
       " 1446.08,\n",
       " 1592.11,\n",
       " 3061.06,\n",
       " 1945.67,\n",
       " 4667.56,\n",
       " 2532.71,\n",
       " 1307.4,\n",
       " 9194.41,\n",
       " 5907.34,\n",
       " 12166.14,\n",
       " 6512.92,\n",
       " 7189.58,\n",
       " 750.46,\n",
       " 9127.05,\n",
       " 5874.38,\n",
       " 1496.34,\n",
       " 717.62,\n",
       " 13444.76,\n",
       " 9849.84,\n",
       " 5091.22,\n",
       " 1130.68,\n",
       " 4234.94,\n",
       " 3414.28,\n",
       " 3146.3,\n",
       " 7515.62,\n",
       " 13277.42,\n",
       " 2565.26,\n",
       " 6387.08,\n",
       " 34291.27,\n",
       " 724.85,\n",
       " 11365.88,\n",
       " 1368.95,\n",
       " 1596.45,\n",
       " 28647.89,\n",
       " 2493.89,\n",
       " 10669.72,\n",
       " 10615.12,\n",
       " 4891.08,\n",
       " 2559.18,\n",
       " 21019.06,\n",
       " 2413.02,\n",
       " 8526.42,\n",
       " 1406.84,\n",
       " 6042.67,\n",
       " 8699.19,\n",
       " 4968.73,\n",
       " 10721.23,\n",
       " 3149.45,\n",
       " 2313.6,\n",
       " 1620.37,\n",
       " 2002.09,\n",
       " 3617.97,\n",
       " 896.91,\n",
       " 12218.98,\n",
       " 1522.45,\n",
       " 1071.51,\n",
       " 2664.7,\n",
       " 19344.47,\n",
       " 1596.59,\n",
       " 8593.97,\n",
       " 3245.0,\n",
       " 10106.86,\n",
       " 1567.79,\n",
       " 2974.18,\n",
       " 4417.05,\n",
       " 2651.42,\n",
       " 10375.52,\n",
       " 1296.46,\n",
       " 1510.56,\n",
       " 21137.1,\n",
       " 5027.39,\n",
       " 3247.07,\n",
       " 2464.3,\n",
       " 12843.71,\n",
       " 3800.97,\n",
       " 5907.97,\n",
       " 2272.02,\n",
       " 3971.34,\n",
       " 24552.27,\n",
       " 5852.05,\n",
       " 1677.68,\n",
       " 14010.61,\n",
       " 3080.82,\n",
       " 2355.42,\n",
       " 2554.38,\n",
       " 4496.93,\n",
       " 2715.22,\n",
       " 5565.9,\n",
       " 3082.98,\n",
       " 2300.6,\n",
       " 8123.04,\n",
       " 1364.62,\n",
       " 4723.0,\n",
       " 6648.79,\n",
       " 3024.38,\n",
       " 2981.92,\n",
       " 27202.04,\n",
       " 1072.99,\n",
       " 1840.46,\n",
       " 9824.35,\n",
       " 712.79,\n",
       " 2413.15,\n",
       " 1048.96,\n",
       " 4414.55,\n",
       " 3545.18,\n",
       " 3303.38,\n",
       " 11587.7,\n",
       " 4699.34,\n",
       " 6018.5,\n",
       " 12772.97,\n",
       " 2089.04,\n",
       " 5702.28,\n",
       " 9073.3,\n",
       " 2829.75,\n",
       " 4751.72,\n",
       " 1834.8,\n",
       " 3936.46,\n",
       " 3393.67,\n",
       " 1799.7,\n",
       " 19621.9,\n",
       " 2280.38,\n",
       " 4199.76,\n",
       " 1757.33,\n",
       " 2777.15,\n",
       " 2438.6,\n",
       " 2156.42,\n",
       " 3675.33,\n",
       " 6195.18,\n",
       " 4018.92,\n",
       " 7945.5,\n",
       " 4771.36,\n",
       " 3108.84,\n",
       " 12949.96,\n",
       " 3016.38,\n",
       " 2033.09,\n",
       " 6533.86,\n",
       " 8641.6,\n",
       " 25922.83,\n",
       " 1423.51,\n",
       " 1143.38,\n",
       " 3594.85,\n",
       " 2861.24,\n",
       " 2892.71,\n",
       " 1890.21,\n",
       " 1806.53,\n",
       " 6202.58,\n",
       " 3557.34,\n",
       " 6986.26,\n",
       " 5022.05,\n",
       " 4359.22,\n",
       " 20031.54,\n",
       " 10783.31,\n",
       " 7234.88,\n",
       " 5949.03,\n",
       " 2007.62,\n",
       " 1894.85,\n",
       " 16833.96,\n",
       " 1667.61,\n",
       " 2858.11,\n",
       " 2345.15,\n",
       " 2451.26,\n",
       " 10691.27,\n",
       " 3771.21,\n",
       " 8029.54,\n",
       " 5065.44,\n",
       " 583.86,\n",
       " 2790.66,\n",
       " 502.98,\n",
       " 2079.62,\n",
       " 17654.89,\n",
       " 1439.94,\n",
       " 2950.16,\n",
       " 18442.68,\n",
       " 1790.34,\n",
       " 1979.08,\n",
       " 5306.39,\n",
       " 608.7,\n",
       " 7064.81,\n",
       " 4381.77,\n",
       " 1140.43,\n",
       " 2867.24,\n",
       " 1401.85,\n",
       " 6120.81,\n",
       " 6579.83,\n",
       " 969.98,\n",
       " 1335.31,\n",
       " 4425.04,\n",
       " 20103.27,\n",
       " 8066.65,\n",
       " 8202.51,\n",
       " 1963.59,\n",
       " 839.21,\n",
       " 5855.9,\n",
       " 3516.64,\n",
       " 36199.54,\n",
       " 21027.59,\n",
       " 5645.87,\n",
       " 4192.82,\n",
       " 2450.23,\n",
       " 4929.31,\n",
       " 30740.88,\n",
       " 5567.68,\n",
       " 4716.38,\n",
       " 1954.08,\n",
       " 2161.17,\n",
       " 4639.93,\n",
       " 5063.24,\n",
       " 6599.34,\n",
       " 3911.97,\n",
       " 2997.98,\n",
       " 5864.54,\n",
       " 3629.64,\n",
       " 9509.07,\n",
       " 9950.29,\n",
       " 856.31,\n",
       " 8748.01,\n",
       " 8618.21,\n",
       " 3874.4,\n",
       " 8849.5,\n",
       " 62424.01,\n",
       " 2454.65,\n",
       " 16284.37,\n",
       " 10884.09,\n",
       " 1596.59,\n",
       " 3325.93,\n",
       " 9620.4,\n",
       " 3359.43,\n",
       " 1315.26,\n",
       " 19515.94,\n",
       " 4920.04,\n",
       " 2089.04,\n",
       " 1853.75,\n",
       " 2348.56,\n",
       " 5897.47,\n",
       " 7477.02,\n",
       " 6180.28,\n",
       " 6793.8,\n",
       " 2943.72,\n",
       " 1206.09,\n",
       " 7958.19,\n",
       " 7376.87,\n",
       " 2667.98,\n",
       " 1996.06,\n",
       " 2975.87,\n",
       " 1973.9,\n",
       " 2831.69,\n",
       " 2067.89,\n",
       " 2304.75,\n",
       " 5875.08,\n",
       " 2174.61,\n",
       " 740.32,\n",
       " 56733.42,\n",
       " 9453.93,\n",
       " 2493.89,\n",
       " 1619.95,\n",
       " 11797.25,\n",
       " 2610.88,\n",
       " 2034.26,\n",
       " 24141.0,\n",
       " 10364.94,\n",
       " 2442.23,\n",
       " 3183.69,\n",
       " 5070.41,\n",
       " 12682.85,\n",
       " 1035.39,\n",
       " 3873.31,\n",
       " 6656.44,\n",
       " 977.77,\n",
       " 662.02,\n",
       " 3014.3,\n",
       " 2610.88,\n",
       " 22230.2,\n",
       " 1853.55,\n",
       " 5264.89,\n",
       " 2650.34,\n",
       " 7967.5,\n",
       " 3360.57,\n",
       " 2523.7,\n",
       " 1481.28,\n",
       " 16680.21,\n",
       " 3078.38,\n",
       " 1952.33,\n",
       " 2155.89,\n",
       " 10077.96,\n",
       " 2557.01,\n",
       " 2829.91,\n",
       " 26418.98,\n",
       " 3189.28,\n",
       " 2350.67,\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = list(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.572</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.569</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   179.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:37:49</td>     <th>  Log-Likelihood:    </th>          <td> -31576.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3107</td>      <th>  AIC:               </th>          <td>6.320e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3084</td>      <th>  BIC:               </th>          <td>6.334e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>posse_de_veiculo</th>              <td>  620.3598</td> <td>  251.164</td> <td>    2.470</td> <td> 0.014</td> <td>  127.894</td> <td> 1112.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>posse_de_imovel</th>               <td>  373.2743</td> <td>  243.141</td> <td>    1.535</td> <td> 0.125</td> <td> -103.460</td> <td>  850.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qtd_filhos</th>                    <td> 1826.0057</td> <td>  810.162</td> <td>    2.254</td> <td> 0.024</td> <td>  237.495</td> <td> 3414.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>idade</th>                         <td>   50.0341</td> <td>   14.035</td> <td>    3.565</td> <td> 0.000</td> <td>   22.516</td> <td>   77.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>                 <td>  500.5046</td> <td>   18.460</td> <td>   27.113</td> <td> 0.000</td> <td>  464.310</td> <td>  536.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qt_pessoas_residencia</th>         <td>-1599.5924</td> <td>  783.873</td> <td>   -2.041</td> <td> 0.041</td> <td>-3136.559</td> <td>  -62.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo_M</th>                        <td> 5551.7584</td> <td>  257.955</td> <td>   21.522</td> <td> 0.000</td> <td> 5045.978</td> <td> 6057.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Bolsista</th>           <td>-1.303e-13</td> <td> 9.25e-13</td> <td>   -0.141</td> <td> 0.888</td> <td>-1.94e-12</td> <td> 1.68e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Empresário</th>         <td>  670.3056</td> <td>  257.436</td> <td>    2.604</td> <td> 0.009</td> <td>  165.543</td> <td> 1175.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Pensionista</th>        <td>-2532.4317</td> <td> 4464.857</td> <td>   -0.567</td> <td> 0.571</td> <td>-1.13e+04</td> <td> 6221.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Servidor público</th>   <td>  243.6870</td> <td>  393.077</td> <td>    0.620</td> <td> 0.535</td> <td> -527.032</td> <td> 1014.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Pós graduação</th>        <td> 1904.3485</td> <td> 2350.586</td> <td>    0.810</td> <td> 0.418</td> <td>-2704.524</td> <td> 6513.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Secundário</th>           <td>  360.9991</td> <td> 1242.924</td> <td>    0.290</td> <td> 0.771</td> <td>-2076.044</td> <td> 2798.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Superior completo</th>    <td> 1185.2046</td> <td> 1248.505</td> <td>    0.949</td> <td> 0.343</td> <td>-1262.782</td> <td> 3633.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Superior incompleto</th>  <td>   69.7507</td> <td> 1343.261</td> <td>    0.052</td> <td> 0.959</td> <td>-2564.025</td> <td> 2703.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estado_civil_Separado</th>         <td>-1670.8368</td> <td>  912.701</td> <td>   -1.831</td> <td> 0.067</td> <td>-3460.401</td> <td>  118.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estado_civil_Solteiro</th>         <td>-2170.4910</td> <td>  820.376</td> <td>   -2.646</td> <td> 0.008</td> <td>-3779.030</td> <td> -561.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estado_civil_União</th>            <td> -284.9811</td> <td>  454.937</td> <td>   -0.626</td> <td> 0.531</td> <td>-1176.991</td> <td>  607.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estado_civil_Viúvo</th>            <td>-1945.8824</td> <td> 1038.404</td> <td>   -1.874</td> <td> 0.061</td> <td>-3981.916</td> <td>   90.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Casa</th>          <td>  145.7936</td> <td>  881.245</td> <td>    0.165</td> <td> 0.869</td> <td>-1582.094</td> <td> 1873.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Com os pais</th>   <td> -191.3341</td> <td>  992.820</td> <td>   -0.193</td> <td> 0.847</td> <td>-2137.989</td> <td> 1755.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Comunitário</th>   <td>  -20.4382</td> <td> 1582.373</td> <td>   -0.013</td> <td> 0.990</td> <td>-3123.051</td> <td> 3082.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Estúdio</th>       <td> 3406.4320</td> <td> 1803.279</td> <td>    1.889</td> <td> 0.059</td> <td> -129.317</td> <td> 6942.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Governamental</th> <td>  842.0091</td> <td> 1099.517</td> <td>    0.766</td> <td> 0.444</td> <td>-1313.851</td> <td> 2997.870</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2748.909</td> <th>  Durbin-Watson:     </th>  <td>   2.060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>141667.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.996</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>35.100</td>  <th>  Cond. No.          </th>  <td>3.45e+18</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The smallest eigenvalue is 4.65e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.572\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.569\n",
       "Method:                 Least Squares   F-statistic:                              179.1\n",
       "Date:                Mon, 06 Mar 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        18:37:49   Log-Likelihood:                         -31576.\n",
       "No. Observations:                3107   AIC:                                  6.320e+04\n",
       "Df Residuals:                    3084   BIC:                                  6.334e+04\n",
       "Df Model:                          23                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "posse_de_veiculo                620.3598    251.164      2.470      0.014     127.894    1112.825\n",
       "posse_de_imovel                 373.2743    243.141      1.535      0.125    -103.460     850.009\n",
       "qtd_filhos                     1826.0057    810.162      2.254      0.024     237.495    3414.517\n",
       "idade                            50.0341     14.035      3.565      0.000      22.516      77.552\n",
       "tempo_emprego                   500.5046     18.460     27.113      0.000     464.310     536.699\n",
       "qt_pessoas_residencia         -1599.5924    783.873     -2.041      0.041   -3136.559     -62.626\n",
       "sexo_M                         5551.7584    257.955     21.522      0.000    5045.978    6057.538\n",
       "tipo_renda_Bolsista           -1.303e-13   9.25e-13     -0.141      0.888   -1.94e-12    1.68e-12\n",
       "tipo_renda_Empresário           670.3056    257.436      2.604      0.009     165.543    1175.069\n",
       "tipo_renda_Pensionista        -2532.4317   4464.857     -0.567      0.571   -1.13e+04    6221.963\n",
       "tipo_renda_Servidor público     243.6870    393.077      0.620      0.535    -527.032    1014.406\n",
       "educacao_Pós graduação         1904.3485   2350.586      0.810      0.418   -2704.524    6513.221\n",
       "educacao_Secundário             360.9991   1242.924      0.290      0.771   -2076.044    2798.043\n",
       "educacao_Superior completo     1185.2046   1248.505      0.949      0.343   -1262.782    3633.191\n",
       "educacao_Superior incompleto     69.7507   1343.261      0.052      0.959   -2564.025    2703.527\n",
       "estado_civil_Separado         -1670.8368    912.701     -1.831      0.067   -3460.401     118.727\n",
       "estado_civil_Solteiro         -2170.4910    820.376     -2.646      0.008   -3779.030    -561.952\n",
       "estado_civil_União             -284.9811    454.937     -0.626      0.531   -1176.991     607.028\n",
       "estado_civil_Viúvo            -1945.8824   1038.404     -1.874      0.061   -3981.916      90.152\n",
       "tipo_residencia_Casa            145.7936    881.245      0.165      0.869   -1582.094    1873.681\n",
       "tipo_residencia_Com os pais    -191.3341    992.820     -0.193      0.847   -2137.989    1755.321\n",
       "tipo_residencia_Comunitário     -20.4382   1582.373     -0.013      0.990   -3123.051    3082.174\n",
       "tipo_residencia_Estúdio        3406.4320   1803.279      1.889      0.059    -129.317    6942.181\n",
       "tipo_residencia_Governamental   842.0091   1099.517      0.766      0.444   -1313.851    2997.870\n",
       "==============================================================================\n",
       "Omnibus:                     2748.909   Durbin-Watson:                   2.060\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           141667.736\n",
       "Skew:                           3.996   Prob(JB):                         0.00\n",
       "Kurtosis:                      35.100   Cond. No.                     3.45e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The smallest eigenvalue is 4.65e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y_test, X_test)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posse_de_veiculo',\n",
       " 'qtd_filhos',\n",
       " 'idade',\n",
       " 'tempo_emprego',\n",
       " 'sexo_M',\n",
       " 'tipo_renda_Empresário',\n",
       " 'educacao_Superior completo',\n",
       " 'tipo_residencia_Estúdio']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backselect = step_reg.backward_regression(X_test, y_test, 0.05,verbose=False)\n",
    "backselect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>       <td>   0.491</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   0.491</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>   1500.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:38:25</td>     <th>  Log-Likelihood:    </th>          <td>-1.2883e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12427</td>      <th>  AIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12419</td>      <th>  BIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>posse_de_veiculo</th>           <td>  -35.2248</td> <td>  148.010</td> <td>   -0.238</td> <td> 0.812</td> <td> -325.347</td> <td>  254.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qtd_filhos</th>                 <td>  -48.2333</td> <td>   85.554</td> <td>   -0.564</td> <td> 0.573</td> <td> -215.933</td> <td>  119.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>idade</th>                      <td>   -4.9706</td> <td>    3.419</td> <td>   -1.454</td> <td> 0.146</td> <td>  -11.673</td> <td>    1.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>              <td>  553.5392</td> <td>   10.951</td> <td>   50.548</td> <td> 0.000</td> <td>  532.074</td> <td>  575.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo_M</th>                     <td> 5817.6929</td> <td>  151.526</td> <td>   38.394</td> <td> 0.000</td> <td> 5520.679</td> <td> 6114.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Empresário</th>      <td>  598.9269</td> <td>  152.777</td> <td>    3.920</td> <td> 0.000</td> <td>  299.461</td> <td>  898.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Superior completo</th> <td>  427.2590</td> <td>  140.878</td> <td>    3.033</td> <td> 0.002</td> <td>  151.117</td> <td>  703.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Estúdio</th>    <td>  480.2440</td> <td>  893.352</td> <td>    0.538</td> <td> 0.591</td> <td>-1270.864</td> <td> 2231.352</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17669.318</td> <th>  Durbin-Watson:     </th>   <td>   2.034</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>10048577.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.217</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>141.335</td>  <th>  Cond. No.          </th>   <td>    549.</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.491\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.491\n",
       "Method:                 Least Squares   F-statistic:                              1500.\n",
       "Date:                Mon, 06 Mar 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        18:38:25   Log-Likelihood:                     -1.2883e+05\n",
       "No. Observations:               12427   AIC:                                  2.577e+05\n",
       "Df Residuals:                   12419   BIC:                                  2.577e+05\n",
       "Df Model:                           8                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "posse_de_veiculo             -35.2248    148.010     -0.238      0.812    -325.347     254.898\n",
       "qtd_filhos                   -48.2333     85.554     -0.564      0.573    -215.933     119.467\n",
       "idade                         -4.9706      3.419     -1.454      0.146     -11.673       1.732\n",
       "tempo_emprego                553.5392     10.951     50.548      0.000     532.074     575.005\n",
       "sexo_M                      5817.6929    151.526     38.394      0.000    5520.679    6114.707\n",
       "tipo_renda_Empresário        598.9269    152.777      3.920      0.000     299.461     898.393\n",
       "educacao_Superior completo   427.2590    140.878      3.033      0.002     151.117     703.401\n",
       "tipo_residencia_Estúdio      480.2440    893.352      0.538      0.591   -1270.864    2231.352\n",
       "==============================================================================\n",
       "Omnibus:                    17669.318   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         10048577.290\n",
       "Skew:                           8.217   Prob(JB):                         0.00\n",
       "Kurtosis:                     141.335   Cond. No.                         549.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_backselect = X[['posse_de_veiculo',\n",
    " 'qtd_filhos',\n",
    " 'idade',\n",
    " 'tempo_emprego',\n",
    " 'sexo_M',\n",
    " 'tipo_renda_Empresário',\n",
    " 'educacao_Superior completo',\n",
    " 'tipo_residencia_Estúdio']]\n",
    "\n",
    "backmodel = sm.OLS(y, X_backselect)\n",
    "backres = backmodel.fit()\n",
    "backres.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "C:\\Users\\feldb\\anaconda3\\lib\\site-packages\\stepwise_regression\\step_reg.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tempo_emprego',\n",
       " 'sexo_M',\n",
       " 'educacao_Superior completo',\n",
       " 'idade',\n",
       " 'posse_de_veiculo',\n",
       " 'tipo_renda_Empresário',\n",
       " 'qt_pessoas_residencia',\n",
       " 'tipo_residencia_Estúdio']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardselect = step_reg.forward_regression(X_test, y_test, 0.05,verbose=False)\n",
    "forwardselect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>       <td>   0.492</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   0.491</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>   1501.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:38:41</td>     <th>  Log-Likelihood:    </th>          <td>-1.2883e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12427</td>      <th>  AIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12419</td>      <th>  BIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>              <td>  553.4760</td> <td>   10.948</td> <td>   50.556</td> <td> 0.000</td> <td>  532.017</td> <td>  574.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo_M</th>                     <td> 5862.1350</td> <td>  153.058</td> <td>   38.300</td> <td> 0.000</td> <td> 5562.117</td> <td> 6162.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Superior completo</th> <td>  456.8915</td> <td>  141.489</td> <td>    3.229</td> <td> 0.001</td> <td>  179.551</td> <td>  734.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>idade</th>                      <td>   -0.1020</td> <td>    4.265</td> <td>   -0.024</td> <td> 0.981</td> <td>   -8.463</td> <td>    8.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>posse_de_veiculo</th>           <td>    5.4593</td> <td>  149.285</td> <td>    0.037</td> <td> 0.971</td> <td> -287.163</td> <td>  298.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Empresário</th>      <td>  612.9827</td> <td>  152.928</td> <td>    4.008</td> <td> 0.000</td> <td>  313.221</td> <td>  912.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qt_pessoas_residencia</th>      <td> -123.3558</td> <td>   62.259</td> <td>   -1.981</td> <td> 0.048</td> <td> -245.393</td> <td>   -1.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_residencia_Estúdio</th>    <td>  471.4677</td> <td>  893.221</td> <td>    0.528</td> <td> 0.598</td> <td>-1279.384</td> <td> 2222.320</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17652.657</td> <th>  Durbin-Watson:     </th>   <td>   2.034</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>10010782.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.202</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>141.074</td>  <th>  Cond. No.          </th>   <td>    550.</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.492\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.491\n",
       "Method:                 Least Squares   F-statistic:                              1501.\n",
       "Date:                Mon, 06 Mar 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        18:38:41   Log-Likelihood:                     -1.2883e+05\n",
       "No. Observations:               12427   AIC:                                  2.577e+05\n",
       "Df Residuals:                   12419   BIC:                                  2.577e+05\n",
       "Df Model:                           8                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "tempo_emprego                553.4760     10.948     50.556      0.000     532.017     574.935\n",
       "sexo_M                      5862.1350    153.058     38.300      0.000    5562.117    6162.153\n",
       "educacao_Superior completo   456.8915    141.489      3.229      0.001     179.551     734.232\n",
       "idade                         -0.1020      4.265     -0.024      0.981      -8.463       8.259\n",
       "posse_de_veiculo               5.4593    149.285      0.037      0.971    -287.163     298.081\n",
       "tipo_renda_Empresário        612.9827    152.928      4.008      0.000     313.221     912.744\n",
       "qt_pessoas_residencia       -123.3558     62.259     -1.981      0.048    -245.393      -1.319\n",
       "tipo_residencia_Estúdio      471.4677    893.221      0.528      0.598   -1279.384    2222.320\n",
       "==============================================================================\n",
       "Omnibus:                    17652.657   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         10010782.201\n",
       "Skew:                           8.202   Prob(JB):                         0.00\n",
       "Kurtosis:                     141.074   Cond. No.                         550.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_forwardselect = X[['tempo_emprego',\n",
    " 'sexo_M',\n",
    " 'educacao_Superior completo',\n",
    " 'idade',\n",
    " 'posse_de_veiculo',\n",
    " 'tipo_renda_Empresário',\n",
    " 'qt_pessoas_residencia',\n",
    " 'tipo_residencia_Estúdio']]\n",
    "\n",
    "forwardmodel = sm.OLS(y, X_forwardselect)\n",
    "forwards = forwardmodel.fit()\n",
    "forwards.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o R², o melhor modelo foi o de regressão linear com todas as variáveis, pois, apresentou o melhor R².\n",
    "\n",
    "Ridge: \n",
    "    \n",
    "R² 0.2847067205249384\n",
    "\n",
    "Lasso:\n",
    "R² 0.2846697676746014\n",
    "\n",
    "Regressão Linear:\n",
    "    \n",
    "R² 0.572\n",
    "\n",
    "Backward\n",
    "R² 0.491\n",
    "\n",
    "Forward: \n",
    "\n",
    "R² 0.492\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Removendo as variáveis comp-value superior a 0.05 não houve alteração no R² dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>       <td>   0.491</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   0.491</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>   3000.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:55:31</td>     <th>  Log-Likelihood:    </th>          <td>-1.2884e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12427</td>      <th>  AIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12423</td>      <th>  BIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>              <td>  541.4504</td> <td>    8.173</td> <td>   66.253</td> <td> 0.000</td> <td>  525.431</td> <td>  557.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo_M</th>                     <td> 5703.0445</td> <td>  127.757</td> <td>   44.640</td> <td> 0.000</td> <td> 5452.620</td> <td> 5953.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Empresário</th>      <td>  515.5418</td> <td>  144.446</td> <td>    3.569</td> <td> 0.000</td> <td>  232.406</td> <td>  798.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Superior completo</th> <td>  343.8478</td> <td>  132.325</td> <td>    2.599</td> <td> 0.009</td> <td>   84.470</td> <td>  603.226</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17732.576</td> <th>  Durbin-Watson:     </th>   <td>   2.033</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>10178345.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.274</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>142.224</td>  <th>  Cond. No.          </th>   <td>    22.2</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.491\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.491\n",
       "Method:                 Least Squares   F-statistic:                              3000.\n",
       "Date:                Mon, 06 Mar 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        19:55:31   Log-Likelihood:                     -1.2884e+05\n",
       "No. Observations:               12427   AIC:                                  2.577e+05\n",
       "Df Residuals:                   12423   BIC:                                  2.577e+05\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "tempo_emprego                541.4504      8.173     66.253      0.000     525.431     557.470\n",
       "sexo_M                      5703.0445    127.757     44.640      0.000    5452.620    5953.469\n",
       "tipo_renda_Empresário        515.5418    144.446      3.569      0.000     232.406     798.678\n",
       "educacao_Superior completo   343.8478    132.325      2.599      0.009      84.470     603.226\n",
       "==============================================================================\n",
       "Omnibus:                    17732.576   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         10178345.448\n",
       "Skew:                           8.274   Prob(JB):                         0.00\n",
       "Kurtosis:                     142.224   Cond. No.                         22.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_backselect = X[[\n",
    " 'tempo_emprego',\n",
    " 'sexo_M',\n",
    " 'tipo_renda_Empresário',\n",
    " 'educacao_Superior completo']]\n",
    "\n",
    "backmodel = sm.OLS(y, X_backselect)\n",
    "backres = backmodel.fit()\n",
    "backres.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>       <td>   0.492</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   0.491</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>   2402.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:56:53</td>     <th>  Log-Likelihood:    </th>          <td>-1.2883e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12427</td>      <th>  AIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12422</td>      <th>  BIC:               </th>           <td>2.577e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo_emprego</th>              <td>  553.4660</td> <td>    9.378</td> <td>   59.018</td> <td> 0.000</td> <td>  535.084</td> <td>  571.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sexo_M</th>                     <td> 5867.4336</td> <td>  142.407</td> <td>   41.202</td> <td> 0.000</td> <td> 5588.294</td> <td> 6146.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educacao_Superior completo</th> <td>  458.3624</td> <td>  139.378</td> <td>    3.289</td> <td> 0.001</td> <td>  185.161</td> <td>  731.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tipo_renda_Empresário</th>      <td>  613.7503</td> <td>  149.232</td> <td>    4.113</td> <td> 0.000</td> <td>  321.233</td> <td>  906.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qt_pessoas_residencia</th>      <td> -123.8444</td> <td>   47.441</td> <td>   -2.611</td> <td> 0.009</td> <td> -216.835</td> <td>  -30.853</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17651.579</td> <th>  Durbin-Watson:     </th>   <td>   2.034</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>10006954.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 8.201</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>141.048</td>  <th>  Cond. No.          </th>   <td>    22.5</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.492\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.491\n",
       "Method:                 Least Squares   F-statistic:                              2402.\n",
       "Date:                Mon, 06 Mar 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        19:56:53   Log-Likelihood:                     -1.2883e+05\n",
       "No. Observations:               12427   AIC:                                  2.577e+05\n",
       "Df Residuals:                   12422   BIC:                                  2.577e+05\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "tempo_emprego                553.4660      9.378     59.018      0.000     535.084     571.848\n",
       "sexo_M                      5867.4336    142.407     41.202      0.000    5588.294    6146.574\n",
       "educacao_Superior completo   458.3624    139.378      3.289      0.001     185.161     731.564\n",
       "tipo_renda_Empresário        613.7503    149.232      4.113      0.000     321.233     906.267\n",
       "qt_pessoas_residencia       -123.8444     47.441     -2.611      0.009    -216.835     -30.853\n",
       "==============================================================================\n",
       "Omnibus:                    17651.579   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         10006954.744\n",
       "Skew:                           8.201   Prob(JB):                         0.00\n",
       "Kurtosis:                     141.048   Cond. No.                         22.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_forwardselect = X[['tempo_emprego',\n",
    " 'sexo_M',\n",
    " 'educacao_Superior completo',\n",
    " 'tipo_renda_Empresário',\n",
    " 'qt_pessoas_residencia']]\n",
    "\n",
    "forwardmodel = sm.OLS(y, X_forwardselect)\n",
    "forwards = forwardmodel.fit()\n",
    "forwards.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15792549.065815398, 51041512.2945975, 66097321.548941225]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "renda = pd.read_csv('previsao_de_renda.csv')\n",
    "renda.drop(['Unnamed: 0', 'id_cliente'], axis=1)\n",
    "renda['posse_de_veiculo'] = renda['posse_de_veiculo'].map({True: 1,False: 0})\n",
    "renda['posse_de_imovel'] = renda['posse_de_imovel'].map({True: 1,False: 0})\n",
    "renda['data_ref'] = pd.to_datetime(renda['data_ref'])\n",
    "renda['data_ref'] = renda['data_ref'].dt.strftime('%m-%Y')\n",
    "            \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, \n",
    "                                                    train_size= 0.75, random_state = 42)\n",
    "\n",
    "regr = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "path = regr.cost_complexity_pruning_path(X_train, y_train)\n",
    "path\n",
    "\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "clfs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    \n",
    "    clf = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "arvores = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    arvores.append(clf)\n",
    "\n",
    "arvores\n",
    "\n",
    "train_scores = [mean_squared_error(y_train , clf.predict(X_train)) for clf in arvores]\n",
    "test_scores  = [mean_squared_error(y_test  , clf.predict(X_test )) for clf in arvores]\n",
    "\n",
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49956117.11155751, 41839049.03019456, 46317122.993746795]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-quadrado na base de treino: 0.82\n"
     ]
    }
   ],
   "source": [
    "arvore_final = DecisionTreeRegressor(random_state = 0)\n",
    "arvore_final.fit(X_train, y_train)\n",
    "print(f\"R-quadrado na base de treino: {arvore_final.score(X_train, y_train):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-quadrado na base de testes: 0.88\n"
     ]
    }
   ],
   "source": [
    "arvore_final = DecisionTreeRegressor(random_state = 0)\n",
    "arvore_final.fit(X_test, y_test)\n",
    "print(f\"R-quadrado na base de testes: {arvore_final.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
